{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from random import random\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        dict = pickle.load(f, encoding=\"latin1\")\n",
    "    return dict\n",
    "\n",
    "#datadict = unpickle('/home/kamarain/Data/cifar-10-batches-py/data_batch_1')\n",
    "datadict = unpickle('C:/Users/danie/Desktop/TUNI/ML-PatternRec/EX2/cifar-10-batches-py/test_batch')\n",
    "\n",
    "X = datadict[\"data\"]\n",
    "Y = datadict[\"labels\"]\n",
    "\n",
    "#labeldict = unpickle('/home/kamarain/Data/cifar-10-batches-py/batches.meta')\n",
    "labeldict = unpickle('C:/Users/danie/Desktop/TUNI/ML-PatternRec/EX2/cifar-10-batches-py/batches.meta')\n",
    "label_names = labeldict[\"label_names\"]\n",
    "\n",
    "\n",
    "#X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "        #ValueError: operands could not be broadcast together with shapes (3072,) (32,32,3)\n",
    "    #Y = np.array(Y)\n",
    "\n",
    "#X = datadict[\"data\"]\n",
    "#Y = datadict[\"labels\"]\n",
    "\n",
    "#for i in range(X.shape[0]):\n",
    "    # Show some images randomly\n",
    " #   if random() > 0.999:\n",
    " #       plt.figure(1);\n",
    " #       plt.clf()\n",
    " #       plt.imshow(X[i])\n",
    " #       plt.title(f\"Image {i} label={label_names[Y[i]]} (num {Y[i]})\")\n",
    " #       plt.pause(1)\n",
    "\n",
    "input_directory= ('C:/Users/danie/Desktop/TUNI/ML-PatternRec/EX2/cifar-10-batches-py/')\n",
    "train_1= unpickle(input_directory+'data_batch_1')\n",
    "train_2= unpickle(input_directory+'data_batch_2')\n",
    "train_3= unpickle(input_directory+'data_batch_3')\n",
    "train_4= unpickle(input_directory+'data_batch_4')\n",
    "train_5= unpickle(input_directory+'data_batch_5')\n",
    "\n",
    "#train_X=np.append(train_1[\"data\"],train_2[\"data\"],train_3[\"data\"],train_4[\"data\"],train_5[\"data\"],axis=0)\n",
    "train_X=np.append(train_1[\"data\"],train_2[\"data\"],axis=0)\n",
    "train_X=np.append(train_X, train_3[\"data\"],axis=0)\n",
    "train_X=np.append(train_X, train_4[\"data\"],axis=0)\n",
    "train_X=np.append(train_X, train_5[\"data\"],axis=0)\n",
    "\n",
    "\n",
    "#print(type(train_1[\"labels\"]))\n",
    "train_Y=train_1[\"labels\"]\n",
    "train_Y.extend(train_2[\"labels\"])\n",
    "train_Y.extend(train_3[\"labels\"])\n",
    "train_Y.extend(train_4[\"labels\"])\n",
    "train_Y.extend(train_5[\"labels\"])\n",
    "\n",
    "train_Y = np.array(train_Y)\n",
    "Y = np.array(Y)\n",
    "print(len(train_Y))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_acc(pred,gt):\n",
    "    temp_val=pred-gt\n",
    "    temp_val_1=temp_val[temp_val==0]\n",
    "    return (temp_val_1.size/pred.size)*100\n",
    "    \n",
    "    #print((temp_val_1.size/pred.size)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_classifier_random(x):\n",
    "    return np.random.randint(0,9,x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_classifier_1nn(x,trdata,trlabels):\n",
    "    n=1\n",
    "    pred=np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        distance=np.ones(trdata.shape[0])*np.inf\n",
    "        smallest_distance=np.inf\n",
    "        smallest_label=None\n",
    "        for j in range (trdata.shape[0]):\n",
    "            temp_distance=math.sqrt(((trdata[j]-x[i])**2).sum()) #euclidean\n",
    "            distance[j]=temp_distance\n",
    "            if temp_distance < smallest_distance:\n",
    "                smallest_distance = temp_distance\n",
    "                smallest_label = trlabels[j]\n",
    "        pred[i]=smallest_label\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random prediction accuracy = 10.08\n"
     ]
    }
   ],
   "source": [
    "random_pred=cifar10_classifier_random(X)\n",
    "rand_acc=class_acc(random_pred,Y)\n",
    "print(\"random prediction accuracy = \"+ str(rand_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1NN prediction accuracy = 25.35\n"
     ]
    }
   ],
   "source": [
    "nn_pred=cifar10_classifier_1nn(X,train_X,train_Y)\n",
    "nn_acc=class_acc(nn_pred,Y)\n",
    "print(\"1NN prediction accuracy = \" +str(nn_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
